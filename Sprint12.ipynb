{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I17rg4QtwK54"
   },
   "source": [
    "# Sprint Deep Learning Scratch Convolutional Neural Network 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H01oQ8hDwK56",
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#About this Sprint\" data-toc-modified-id=\"About this Sprint-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>About this Sprint</a></span><ul class=\"toc-item\"><li><span><a href=\"#Purpose of this Sprint\" data-toc-modified-id=\"Purpose of this Sprint-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Purpose of this Sprint</a></span></li><li><span><a href=\"#How to learn\" data-toc-modified-id=\"How to learn-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>How to learn</a></span></li></ul></li><li><span><a href=\"#2D Convolutional Neural Network Scratch\" data-toc-modified-id=\"2D Convolutional Neural Network Scratch\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>2D Convolutional Neural Network Scratch</a></span><ul class=\"toc-item\"><li><span><a href=\"#Preparing the data set\" data-toc-modified-id=\"Preparing the data set-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Preparing the data set</a></span></li><li><span><a href=\"#Preparation for NN classes and other classes so far\" data-toc-modified-id=\"Preparation for NN classes and other classes so far-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Preparation for NN classes and other classes so far</a></span><ul class=\"toc-item\"><li><span><a href=\"#fully-coonected layer\" data-toc-modified-id=\"fully-coonected layer-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>fully-coonected layer</a></span></li><li><span><a href=\"#initialization\" data-toc-modified-id=\"initialization-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>initialization</a></span></li><li><span><a href=\"#optimization\" data-toc-modified-id=\"optimization-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>optimization</a></span></li><li><span><a href=\"#activation function\" data-toc-modified-id=\"activation function-2.2.4\"><span class=\"toc-item-num\">2.2.4&nbsp;&nbsp;</span>activation function</a></span></li><li><span><a href=\"#Mini Batch\" data-toc-modified-id=\"Mini Batch-2.2.5\"><span class=\"toc-item-num\">2.2.5&nbsp;&nbsp;</span>Mini Batch</a></span></li></ul></li><li><span><a href=\"#【Problem 1】Creating a 2-D convolutional layer\" data-toc-modified-id=\"【Problem 1】Creating a 2-D convolutional layer-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>【Problem 1】Creating a 2-D convolutional layer</a></span><ul class=\"toc-item\"><li><span><a href=\"#convolutional layer class\" data-toc-modified-id=\"convolutional layer class-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>convolutional layer class</a></span></li></ul></li><li><span><a href=\"#【Problem 2】Output size after 2-D convolution\" data-toc-modified-id=\"【Problem 2】Output size after 2-D convolution-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>【Problem 2】Output size after 2-D convolution</a></span><ul class=\"toc-item\"><li><span><a href=\"#Experiments on 2-D convolution\" data-toc-modified-id=\"Experiments on 2-D convolution-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>Experiments on 2-D convolution</a></span></li></ul></li><li><span><a href=\"#【Problem 3】Create a maximum pooling layer\" data-toc-modified-id=\"【Problem 3】Create a maximum pooling layer-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>【Problem 3】Create a maximum pooling layer</a></span></li><li><span><a href=\"#【Problem 4】(Advanced Problem ) Creating an Average Pooling\" data-toc-modified-id=\"【Problem 4】(Advanced Problem ) Creating an Average Pooling-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>【Problem 4】(Advanced Problem ) Creating an Average Pooling</a></span></li><li><span><a href=\"#【Problem 5】Flatten\" data-toc-modified-id=\"【Problem 5】Flatten-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>【Problem 5】Flatten</a></span></li><li><span><a href=\"#【Problem 6】Learning and Estimation\" data-toc-modified-id=\"【Problem 6】Learning and Estimation-2.8\"><span class=\"toc-item-num\">2.8&nbsp;&nbsp;</span>【Problem 6】Learning and Estimation</a></span></li><li><span><a href=\"#【Problem 7】（(Advanced Problem) LeNet\" data-toc-modified-id=\"【Problem 7】（(Advanced Problem) LeNet-2.9\"><span class=\"toc-item-num\">2.9&nbsp;&nbsp;</span>【Problem 7】（(Advanced Problem) LeNet</a></span></li><li><span><a href=\"#【Problem 8】(Advanced Problem) Survey of famous image recognition models\" data-toc-modified-id=\"【Problem 8】(Advanced Assignment) Survey of famous image recognition models-2.10\"><span class=\"toc-item-num\">2.10&nbsp;&nbsp;</span>【Problem 8】(Advanced Assignment) Survey of famous image recognition models</a></span></li><li><span><a href=\"#【Problem 9】Calculate output size and number of parameters\" data-toc-modified-id=\"【Problem 9】Calculate output size and number of parameters-2.11\"><span class=\"toc-item-num\">2.11&nbsp;&nbsp;</span>【Problem 9】Calculate output size and number of parameters</a></span></li><li><span><a href=\"#【Problem 10】(Advanced Problem) Survey on Filter Size\" data-toc-modified-id=\"【Problem 10】(Advanced Problem) Survey on Filter Size-2.12\"><span class=\"toc-item-num\">2.12&nbsp;&nbsp;</span>【Problem 10】(Advanced Problem) Survey on Filter Size</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j1YEIxerwK58"
   },
   "source": [
    "## About this Sprint\n",
    "## Purpose of the Sprint.\n",
    "* Understand the basics of CNNs through scratching.\n",
    "\n",
    "### How to learn\n",
    "After implementing a convolutional neural network for 2D in scratch, we will train and verify it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Tt9LxW2wK58"
   },
   "source": [
    "## Convolutional Neural Network for 2D Scratch\n",
    "We will create a convolutional neural network (CNN) class for 2D from scratch.  \n",
    "We will implement the algorithm using only minimal libraries such as NumPy.  \n",
    "  \n",
    "We will also create a pooling layer to complete the basic form of the CNN.  \n",
    "The name of the class should be Scratch2dCNNClassifier.\n",
    "\n",
    "### Prepare the dataset.\n",
    "We will continue to use the MNIST dataset, inputting a 28x28 image into the 2D convolutional layer.\n",
    "\n",
    "In this case, there is only one channel because it is a black and white image, but we need to prepare the axes in the channel direction.\n",
    "\n",
    "It should be in the form of either NCHW with (n_samples, n_channels, height, width) or NHWC with (n_samples, height, width, n_channels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CKpJ0HshwK59"
   },
   "outputs": [],
   "source": [
    "# Import\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Evaluation index\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "tQ6ECcWdwK5-"
   },
   "outputs": [],
   "source": [
    "# Download the MNIST dataset\n",
    "from keras.datasets import mnist\n",
    "(X, y), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ZqBOBuCiwK5-",
    "outputId": "5ae903d7-1050-41ed-c8f5-2fab4956fc3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000, 28, 28)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "# Check the data\n",
    "print(X.shape) # (60000, 28, 28)\n",
    "print(X.shape) # (10000, 28, 28)\n",
    "print(X[0].dtype) # uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "A2RmCiqawK6A",
    "outputId": "d9db4ece-a726-4957-d0d7-6ce646be63a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Type conversion, normalization\n",
    "X = X.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X /= 255\n",
    "X_test /= 255\n",
    "print(X.max()) # 1.0\n",
    "print(X.min()) # 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "e0uQj2znwK6A",
    "outputId": "4e10b1a5-3647-488b-817b-ddfee58996f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 10)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding of correct label value\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_one_hot = enc.fit_transform(y[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "print(y.shape) # (60000,)\n",
    "print(y_one_hot.shape) # (60000, 10)\n",
    "print(y_one_hot.dtype) # float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QpkwfoPswK6B",
    "outputId": "4f1f6eac-7d23-44e6-eb08-3c80d857699a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 28, 28)\n",
      "(12000, 28, 28)\n",
      "(48000, 10)\n",
      "(12000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Split into training data and validation data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y_one_hot, test_size=0.2)\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_train.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbqbCRZ4wK6B"
   },
   "source": [
    "### Preparing for NN classes and other activities so far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEIcp2bPwK6C"
   },
   "source": [
    "#### All binding layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "duKjHNocwK6C"
   },
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    Fully connected layers from number of nodes n_nodes1 to n_nodes2\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      Number of nodes in the previous layer\n",
    "    n_nodes2 : int\n",
    "      Number of nodes in subsequent layers\n",
    "    initializer : Instances of initialization methods\n",
    "    optimizer : Instances of optimization methods\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer, activation):\n",
    "        \n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.initializer = initializer\n",
    "        self.optimizer = optimizer\n",
    "        self.activation = activation\n",
    "        # Initialize.\n",
    "        # Use the initializer method to initialize self.W and self.B\n",
    "        self.W = self.initializer.W(self.n_nodes1,self.n_nodes2)\n",
    "        self.B = self.initializer.B(self.n_nodes2)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Forward\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray of the following form, shape (batch_size, n_nodes1)\n",
    "            Input\n",
    "        Returns\n",
    "        ----------\n",
    "        A : ndarray of the following form, shape (batch_size, n_nodes2)\n",
    "            Output\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.A = np.dot(self.X,self.W) + self.B\n",
    "        \n",
    "        return self.activation.forward(self.A)\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        Backward\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : ndarray of the following form, shape (batch_size, n_nodes2)\n",
    "            The gradient flowed in from behind.\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : ndarray of the following form, shape (batch_size, n_nodes1)\n",
    "            forward slope\n",
    "        \"\"\"\n",
    "        dA = self.activation.backward(dZ)\n",
    "        self.dB = np.mean(dA,axis=0)\n",
    "        self.dW = np.dot(self.X.T,dA)/len(self.X)\n",
    "        dZ = np.dot(dA,self.W.T)\n",
    "        \n",
    "        # Update\n",
    "        self = self.optimizer.update(self)\n",
    "        \n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmW0YtuQwK6C"
   },
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "uD3iuDwMwK6D"
   },
   "outputs": [],
   "source": [
    "class SimpleInitializerConv2d:\n",
    "    \"\"\"\n",
    "    Simple initialization with Gaussian distribution\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      Standard deviation of Gaussian distribution\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma=0.01):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self, F, C, FH, FW):\n",
    "        \"\"\"\n",
    "        Initializing weights\n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        W : weight\n",
    "        \"\"\"\n",
    "        return self.sigma * np.random.randn(F,C,FH,FW)\n",
    "    \n",
    "    def B(self, F):\n",
    "        \"\"\"\n",
    "        Bias initialization\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B : bias\n",
    "        \"\"\"\n",
    "        return np.zeros(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "AgMADoK2wK6D"
   },
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    Simple initialization with Gaussian distribution\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      Standard deviation of Gaussian distribution\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        Initializing weights\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          Number of nodes in the previous layer\n",
    "        n_nodes2 : int\n",
    "          Number of nodes in subsequent layers\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W : weight\n",
    "        \"\"\"\n",
    "        return self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        Bias initialization\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          Number of nodes in subsequent layers\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B : bias\n",
    "        \"\"\"\n",
    "        return np.zeros(n_nodes2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ILn8pHVEwK6D"
   },
   "outputs": [],
   "source": [
    "class HeInitializer():\n",
    "    \"\"\"\n",
    "    Initialization of weights by He\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        Initializing weights\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          Number of nodes in the previous layer\n",
    "        n_nodes2 : int\n",
    "          Number of nodes in subsequent layers\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W : weight\n",
    "        \"\"\"\n",
    "        return np.random.randn(n_nodes1, n_nodes2)*np.sqrt(2/n_nodes1)\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        Bias initialization\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          Number of nodes in subsequent layers\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B : bias\n",
    "        \"\"\"\n",
    "        return np.zeros(n_nodes2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNM2Pm7ywK6E"
   },
   "source": [
    "#### optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "EiF2CLhvwK6E"
   },
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    stochastic gradient descent method\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : learning rate\n",
    "    \"\"\"\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        Updating the weights and biases of a layer\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : An instance of the layer before the update\n",
    "        \"\"\"\n",
    "        layer.W -= self.lr*layer.dW\n",
    "        layer.B -= self.lr*layer.dB\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "--IzRaSSwK6E"
   },
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    \"\"\"\n",
    "    stochastic gradient descent method\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : learning rate\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        self.hW = 0\n",
    "        self.hB = 0\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        Updating the weights and biases of a layer\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : An instance of the layer before the update\n",
    "        \"\"\"\n",
    "        self.hW += layer.dW*layer.dW\n",
    "        self.hB = layer.dB*layer.dB\n",
    "    \n",
    "        layer.W -= self.lr*layer.dW/(np.sqrt(self.hW) +1e-7)\n",
    "        layer.B -= self.lr*layer.dB/(np.sqrt(self.hB) +1e-7)\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GeRr3GtWwK6E"
   },
   "source": [
    "#### Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "PcVZwcE_wK6F"
   },
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    \"\"\"\n",
    "    Activation function : ReLU function\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def forward(self,A):\n",
    "        self.A = A\n",
    "        return np.maximum(self.A,0)\n",
    "    \n",
    "    def backward(self,dZ):\n",
    "        \n",
    "        return np.where(self.A>0,dZ,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Zc3bzSARwK6F"
   },
   "outputs": [],
   "source": [
    "class Softmax():\n",
    "    \"\"\"\n",
    "    Activation Function : Softmax Function\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def forward(self,A):\n",
    "        \n",
    "        return np.exp(A-np.max(A))/np.sum(np.exp(A-np.max(A)),axis=1,keepdims=True)\n",
    "    \n",
    "    def backward(self,dZ):\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnOfhzHiwK6F"
   },
   "source": [
    "#### Mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "EqOiXryIwK6F"
   },
   "outputs": [],
   "source": [
    "# Mini-batch processing class\n",
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    Iterator to get the mini-batch\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray of the following form, shape (n_samples, n_features)\n",
    "      Training data\n",
    "    y : ndarray of the following form, shape (n_samples, 1)\n",
    "      correct value\n",
    "    batch_size : int\n",
    "      Batch size\n",
    "    seed : int\n",
    "      Seeding random numbers in NumPy\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=None):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    \n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1] \n",
    "    \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2fxdDrkwK6F"
   },
   "source": [
    "### 【Problem 1】Creating a 2-D convolutional layer\n",
    "Expand the class Conv1d of 1D convolutional layers to create the class Conv2d of 2D convolutional layers.\n",
    "\n",
    "The formula for forward propagation is as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WGQfEoYwK6G"
   },
   "source": [
    "$$a_{i,j,m} = \\sum_{k=0}^{K-1}\\sum_{s=0}^{F_{h}-1}\\sum_{t=0}^{F_{w}-1}x_{(i+s),(j+t),k}w_{s,t,k,m}+b_{m}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_G5tefgwK6G"
   },
   "source": [
    "#### convolutional layer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "9q7iydz8wK6H"
   },
   "outputs": [],
   "source": [
    "# 2d convolutional layer class\n",
    "class SimpleConv2d():\n",
    "    \"\"\"\n",
    "    2-D convolutional layer\n",
    "    Parameters\n",
    "    ----------\n",
    "    initializer : Instances of initialization methods\n",
    "    optimizer : Instances of optimization methods\n",
    "    \"\"\"\n",
    "    def __init__(self, F, C, FH, FW, P, S,\n",
    "                 initializer=None,optimizer=None,activation=None):\n",
    "        self.P = P\n",
    "        self.S = S\n",
    "        self.initializer = initializer\n",
    "        self.optimizer = optimizer\n",
    "        self.activation = activation\n",
    "        \n",
    "        # Initialize.\n",
    "        # Use the initializer method to initialize self.W and self.B\n",
    "        self.W = self.initializer.W(F,C,FH,FW)\n",
    "        self.B = self.initializer.B(F)\n",
    "        \n",
    "    def output_shape2d(self,H,W,PH,PW,FH,FW,SH,SW):\n",
    "        OH = (H +2*PH -FH)/SH +1\n",
    "        OW = (W +2*PW -FW)/SW +1\n",
    "        return int(OH),int(OW)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        forward \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray of the following form, shape (batch_size, n_nodes1)\n",
    "            Input\n",
    "        Returns\n",
    "        ----------\n",
    "        A : ndarray of the following form, shape (batch_size, n_nodes2)\n",
    "            Output\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        N,C,H,W = self.X.shape\n",
    "        F,C,FH,FW = self.W.shape\n",
    "        \n",
    "        OH,OW = self.output_shape2d(H,W,self.P,self.P,FH,FW,self.S,self.S)\n",
    "        \n",
    "        self.params = N,C,H,W,F,FH,FW,OH,OW\n",
    "\n",
    "        A = np.zeros([N,F,OH,OW])\n",
    "\n",
    "        self.X_pad = np.pad(self.X,((0,0),(0,0),(self.P,self.P),(self.P,self.P)))\n",
    "\n",
    "        # Batch\n",
    "        for n in range(N):\n",
    "            # Output channels\n",
    "            for ch in range(F):\n",
    "                # Vertical slide\n",
    "                for row in range(0,H,self.S):\n",
    "                    # Horizontal Slide\n",
    "                    for col in range(0,W,self.S):\n",
    "                        A[n,ch,row,col] = \\\n",
    "                        np.sum(self.X_pad[n,:,row:row+FH,col:col+FW]\n",
    "                               *self.W[ch,:,:,:]) \\\n",
    "                        +self.B[ch]\n",
    "        \n",
    "        return  self.activation.forward(A)\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \"\"\"\n",
    "        backward\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : ndarray of the following form, shape (batch_size, n_nodes2)\n",
    "            The gradient flowed in from behind.\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : ndarray of the following form, shape (batch_size, n_nodes1)\n",
    "            forward slope\n",
    "        \"\"\"\n",
    "        \n",
    "        dA = self.activation.backward(dZ)\n",
    "        N,C,H,W,F,FH,FW,OH,OW = self.params\n",
    "        \n",
    "        dZ = np.zeros(self.X_pad.shape)\n",
    "        self.dW = np.zeros(self.W.shape)\n",
    "        self.dB = np.zeros(self.B.shape)\n",
    "        \n",
    "        # dZ\n",
    "        # Batch\n",
    "        for n in range(N):\n",
    "            # Output channels\n",
    "            for ch in range(F):\n",
    "                # Vertical slide\n",
    "                for row in range(0,H,self.S):\n",
    "                    # Horizontal Slide\n",
    "                    for col in range(0,W,self.S):\n",
    "                        dZ[n,:,row:row+FH,col:col+FW] += dA[n,ch,row,col]*self.W[ch,:,:,:]\n",
    "                \n",
    "        dl_rows = range(self.P),range(H+self.P,H+2*self.P,1)\n",
    "        dl_cols = range(self.P),range(W+self.P,W+2*self.P,1)\n",
    "\n",
    "        dZ = np.delete(dZ,dl_rows,axis=2)\n",
    "        dZ = np.delete(dZ,dl_cols,axis=3)\n",
    "                \n",
    "        # dW\n",
    "        # Batch\n",
    "        for n in range(N):\n",
    "            # Output channels\n",
    "            for ch in range(F):\n",
    "                # Vertical slide\n",
    "                for row in range(OH):\n",
    "                    # Horizontal Slide\n",
    "                    for col in range(OW):\n",
    "                        self.dW[ch,:,:,:] += dA[n,ch,row,col]*self.X_pad[n,:,row:row+FH,col:col+FW]\n",
    "        \n",
    "        # dB\n",
    "        # Output channels\n",
    "        for ch in range(F):\n",
    "            self.dB[ch] = np.sum(dA[:,ch,:,:])\n",
    "        \n",
    "        # Update\n",
    "        self = self.optimizer.update(self)\n",
    "        \n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Hwp3fknwK6H"
   },
   "source": [
    "### 【Problem 2】Output size after 2-D convolution\n",
    "Convolution changes the size of the feature map.  \n",
    "How it changes can be obtained from the following formula.  \n",
    "Create a function to do this calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "5kG8fOwXwK6I"
   },
   "outputs": [],
   "source": [
    "def output_shape2d(IH=5,IW=5,PH=0,PW=0,FH=3,FW=3,SH=1,SW=1):\n",
    "    OH = (IH +2*PH -FH)/SH +1\n",
    "    OW = (IW +2*PW -FW)/SW +1\n",
    "    return int(OH),int(OW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "3_fksagCwK6I",
    "outputId": "63ff990b-c074-4ee5-e55f-441fcfd08b1e",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4)\n"
     ]
    }
   ],
   "source": [
    "print(output_shape2d(IH=6,IW=6,PH=0,PW=0,FH=3,FW=3,SH=1,SW=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8_bnJMtwK6I"
   },
   "source": [
    "#### Experiment with 2D convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "0GlEE_HowK6I",
    "outputId": "9fb83ce0-330a-48d0-c4ba-b4b13a1380ee",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.shape: (5, 4, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "N,C,H,W = (5,1,28,28)\n",
    "F,C,FH,FW = (4,1,3,3)\n",
    "\n",
    "S = 1 #Fixed for now\n",
    "P = 1\n",
    "\n",
    "OH,OW = output_shape2d(H,W,P,P,FH,FW,S,S)\n",
    "\n",
    "A = np.zeros([N,F,OH,OW])\n",
    "\n",
    "X_sample = X[0:N].reshape(N,C,H,W)\n",
    "X_pad = np.pad(X_sample,((0,0),(0,0),(P,P),(P,P)))\n",
    "w = np.ones([F,C,FH,FW])\n",
    "B = np.ones(F)\n",
    "\n",
    "# Forward\n",
    "\n",
    "# Batch\n",
    "for n in range(N):\n",
    "    # Output channels\n",
    "    for ch in range(F):\n",
    "        # Vertical slide\n",
    "        for row in range(0,H,S):\n",
    "            # Horizontal Slide\n",
    "            for col in range(0,W,S):\n",
    "                A[n,ch,row,col] = \\\n",
    "                np.sum(X_pad[n,:,row:row+FH,col:col+FW]*w[ch,:,:,:]) +B[ch]\n",
    "                \n",
    "print('A.shape:',A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "k6q-XJLqwK6J",
    "outputId": "a8ec0b8b-fd21-4c50-d045-b6dd383f9901"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dZ.shape: (5, 1, 28, 28)\n",
      "dW.shape: (4, 1, 3, 3)\n",
      "dB.shape: (4,)\n"
     ]
    }
   ],
   "source": [
    "# Backward\n",
    "dA = np.ones(A.shape)\n",
    "\n",
    "dZ = np.zeros(X_pad.shape)\n",
    "dW = np.zeros(w.shape)\n",
    "dB = np.zeros(B.shape)\n",
    "\n",
    "# dZ\n",
    "# Batch\n",
    "for n in range(N):\n",
    "    # Output channels\n",
    "    for ch in range(F):\n",
    "        # Vertical slide\n",
    "        for row in range(0,H,S):\n",
    "            # Horizontal Slide\n",
    "            for col in range(0,W,S):\n",
    "                dZ[n,:,row:row+FH,col:col+FW] += dA[n,ch,row,col]*w[ch,:,:,:]\n",
    "                \n",
    "dl_rows = range(P),range(H+P,H+2*P,1)\n",
    "dl_cols = range(P),range(W+P,W+2*P,1)\n",
    "\n",
    "dZ = np.delete(dZ,dl_rows,axis=2)\n",
    "dZ = np.delete(dZ,dl_cols,axis=3)\n",
    "                \n",
    "# dW\n",
    "# Batch\n",
    "for n in range(N):\n",
    "    # Output channels\n",
    "    for ch in range(F):\n",
    "        # Vertical slide\n",
    "        for row in range(OH):\n",
    "            # Horizontal Slide\n",
    "            for col in range(OW):\n",
    "                dW[ch,:,:,:] += dA[n,ch,row,col]*X_pad[n,:,row:row+FH,col:col+FW]\n",
    "                \n",
    "# dB\n",
    "# Output channels\n",
    "for ch in range(F):\n",
    "    dB[ch] = np.sum(dA[:,ch,:,:])\n",
    "                \n",
    "print('dZ.shape:',dZ.shape)\n",
    "print('dW.shape:',dW.shape)\n",
    "print('dB.shape:',dB.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6VkJ-KlgwK6J"
   },
   "source": [
    "### 【Problem 3】Creating a maximum pooling layer\n",
    "Create a class MaxPool2D for the maximum pooling layer.  \n",
    "Some parts of the pooling layer are easier to understand if they are not expressed in mathematical form, but if they are expressed in mathematical form, the forward propagation looks like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ViTwMwPvwK6J"
   },
   "outputs": [],
   "source": [
    "class MaxPool2D():\n",
    "    \n",
    "    def __init__(self,P):\n",
    "        self.P = P\n",
    "        self.PA = None\n",
    "        self.Pindex = None\n",
    "        \n",
    "    def forward(self,A):\n",
    "        N,F,OH,OW = A.shape\n",
    "        PS = self.P\n",
    "        PH,PW = int(OH/PS),int(OW/PS)\n",
    "        \n",
    "        self.params = N,F,OH,OW,PS,PH,PW\n",
    "        \n",
    "        # Pooling filter\n",
    "        self.PA = np.zeros([N,F,PH,PW])\n",
    "        self.Pindex = np.zeros([N,F,PH,PW])\n",
    "        \n",
    "        for n in range(N):\n",
    "            # Output channels\n",
    "            for ch in range(F):\n",
    "                # Vertical slide\n",
    "                for row in range(PH):\n",
    "                    # Horizontal Slide\n",
    "                    for col in range(PW):\n",
    "                        self.PA[n,ch,row,col] = \\\n",
    "                        np.max(A[n,ch,row*PS:row*PS+PS,col*PS:col*PS+PS])\n",
    "                        \n",
    "                        self.Pindex[n,ch,row,col] = \\\n",
    "                        np.argmax(A[n,ch,row*PS:row*PS+PS,col*PS:col*PS+PS])\n",
    "                        \n",
    "        return self.PA\n",
    "    \n",
    "    def backward(self,dA):\n",
    "        \n",
    "        N,F,OH,OW,PS,PH,PW = self.params\n",
    "        dP = np.zeros([N,F,OH,OW])\n",
    "        \n",
    "        for n in range(N):\n",
    "            # Output channels\n",
    "            for ch in range(F):\n",
    "                # Vertical slide\n",
    "                for row in range(PH):\n",
    "                    # Horizontal Slide\n",
    "                    for col in range(PW):\n",
    "                        idx = self.Pindex[n,ch,row,col]\n",
    "                        tmp = np.zeros((PS*PS))\n",
    "                        for i in range(PS*PS):\n",
    "                            if i == idx:\n",
    "                                tmp[i] = dA[n,ch,row,col]\n",
    "                            else:\n",
    "                                tmp[i] = 0\n",
    "                        dP[n,ch,row*PS:row*PS+PS,col*PS:col*PS+PS] = tmp.reshape(PS,PS)\n",
    "        \n",
    "        return dP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "_K85cvI6wK6J",
    "outputId": "9725b784-ad28-44a2-8be3-aa1fe3688e87",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[8 3 3 1 5 1]\n",
      "   [5 6 3 8 2 1]\n",
      "   [5 5 2 7 4 6]\n",
      "   [3 1 5 5 6 6]\n",
      "   [7 7 1 5 0 2]\n",
      "   [8 3 0 3 4 6]]]]\n"
     ]
    }
   ],
   "source": [
    "X = np.random.randint(0,9,36).reshape(1,1,6,6)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "BvKBDUFAwK6J",
    "outputId": "9320faa4-7022-4322-966c-b5dc53552386",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 3, 3)\n",
      "[[[[8. 8. 5.]\n",
      "   [5. 7. 6.]\n",
      "   [8. 5. 6.]]]]\n"
     ]
    }
   ],
   "source": [
    "Pooling = MaxPool2D(P=2)\n",
    "A = Pooling.forward(X)\n",
    "\n",
    "print(A.shape)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "y2G8YfJCwK6K",
    "outputId": "6fabf8d5-9579-4a99-c33d-fe49520636c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0., 3., 0.],\n",
       "         [0., 1., 1.],\n",
       "         [2., 1., 3.]]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pooling.Pindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "8_Wih4miwK6K",
    "outputId": "9bcbfb8a-5df0-40e0-8bec-5e8809089c4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1 3 0]\n",
      "   [4 2 0]\n",
      "   [1 5 2]]]]\n"
     ]
    }
   ],
   "source": [
    "dA = np.random.randint(0,9,9).reshape(A.shape)\n",
    "print(dA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "xL5y1XmHwK6K",
    "outputId": "6ab016bb-2b43-4122-8994-9719d3ea03f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1. 0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 3. 0. 0.]\n",
      "   [4. 0. 0. 2. 0. 0.]\n",
      "   [0. 0. 0. 0. 0. 0.]\n",
      "   [0. 0. 0. 5. 0. 0.]\n",
      "   [1. 0. 0. 0. 0. 2.]]]]\n"
     ]
    }
   ],
   "source": [
    "dZ = Pooling.backward(dA)\n",
    "\n",
    "print(dZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MMhiYqepwK6L"
   },
   "source": [
    "### 【Problem 4】(Advanced Problem) Creating Average Pooling\n",
    "Create a class AveragePool2D for the average pooling layer.\n",
    "\n",
    "This is a pooling layer that outputs the average value instead of the maximum value in a range.\n",
    "\n",
    "In image recognition, the maximum pooling layer is commonly used, while the average pooling is not often used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "th8daQ5kwK6L"
   },
   "outputs": [],
   "source": [
    "class AveragePool2D():\n",
    "    \n",
    "    def __init__(self,P):\n",
    "        self.P = P\n",
    "        self.PA = None\n",
    "        self.Pindex = None\n",
    "        \n",
    "    def forward(self,A):\n",
    "        N,F,OH,OW = A.shape\n",
    "        PS = self.P\n",
    "        PH,PW = int(OH/PS),int(OW/PS)\n",
    "        \n",
    "        self.params = N,F,OH,OW,PS,PH,PW\n",
    "        \n",
    "        # Pooling filter\n",
    "        self.PA = np.zeros([N,F,PH,PW])\n",
    "        \n",
    "        for n in range(N):\n",
    "            # Output channels\n",
    "            for ch in range(F):\n",
    "                # Vertical slide\n",
    "                for row in range(PH):\n",
    "                    # Horizontal Slide\n",
    "                    for col in range(PW):\n",
    "                        self.PA[n,ch,row,col] = \\\n",
    "                        np.mean(A[n,ch,row*PS:row*PS+PS,col*PS:col*PS+PS])\n",
    "                        \n",
    "        return self.PA\n",
    "    \n",
    "    def backward(self,dA):\n",
    "        \n",
    "        N,F,OH,OW,PS,PH,PW = self.params\n",
    "        dP = np.zeros([N,F,OH,OW])\n",
    "        \n",
    "        for n in range(N):\n",
    "            # Output channels\n",
    "            for ch in range(F):\n",
    "                # Vertical slide\n",
    "                for row in range(PH):\n",
    "                    # Horizontal Slide\n",
    "                    for col in range(PW):\n",
    "                        tmp = np.zeros((PS*PS))\n",
    "                        for i in range(PS*PS):\n",
    "                            tmp[i] = dA[n,ch,row,col]/(PS*PS)\n",
    "\n",
    "                        dP[n,ch,row*PS:row*PS+PS,col*PS:col*PS+PS] = tmp.reshape(PS,PS)\n",
    "        \n",
    "        return dP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "1GZeorsTwK6L",
    "outputId": "6ae24f6f-42ae-44a1-804d-f75085a916ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[2 4 4 3 7 4]\n",
      "   [0 6 7 4 0 1]\n",
      "   [8 5 1 6 5 0]\n",
      "   [3 5 0 2 5 8]\n",
      "   [5 2 1 6 8 7]\n",
      "   [6 2 2 7 4 1]]]]\n"
     ]
    }
   ],
   "source": [
    "X = np.random.randint(0,9,36).reshape(1,1,6,6)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "FMOZpmCNwK6L",
    "outputId": "2d922120-ff00-4434-9b28-462dbe258080"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 3, 3)\n",
      "[[[[3.   4.5  3.  ]\n",
      "   [5.25 2.25 4.5 ]\n",
      "   [3.75 4.   5.  ]]]]\n"
     ]
    }
   ],
   "source": [
    "Pooling = AveragePool2D(P=2)\n",
    "A = Pooling.forward(X)\n",
    "\n",
    "print(A.shape)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "khNbmi_kwK6M",
    "outputId": "ba09c2d5-8707-4cdd-8f80-51198a7760e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[7 6 8]\n",
      "   [2 2 6]\n",
      "   [7 7 1]]]]\n"
     ]
    }
   ],
   "source": [
    "dA = np.random.randint(0,9,9).reshape(A.shape)\n",
    "print(dA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "5njJx88SwK6M",
    "outputId": "c08059aa-7de8-46e0-c069-9541e5c08fb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1.75 1.75 1.5  1.5  2.   2.  ]\n",
      "   [1.75 1.75 1.5  1.5  2.   2.  ]\n",
      "   [0.5  0.5  0.5  0.5  1.5  1.5 ]\n",
      "   [0.5  0.5  0.5  0.5  1.5  1.5 ]\n",
      "   [1.75 1.75 1.75 1.75 0.25 0.25]\n",
      "   [1.75 1.75 1.75 1.75 0.25 0.25]]]]\n"
     ]
    }
   ],
   "source": [
    "dZ = Pooling.backward(dA)\n",
    "\n",
    "print(dZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdMUr2VLwK6M"
   },
   "source": [
    "### 【Problem 5】Flatten\n",
    "Create a Flatten class for smoothing.\n",
    "\n",
    "In the forward direction, reshape the three dimensions of channel, height, and width to one dimension. The values are recorded and reshaped again in the backward direction.\n",
    "\n",
    "By sandwiching this smoothing class in between, we can create an array suitable for all coupled layers before output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "CGFt2uxFwK6M"
   },
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    def __ini__(self,):\n",
    "        pass\n",
    "    def forward(self,X):\n",
    "        self.shape = X.shape\n",
    "        return X.reshape(len(X),-1)\n",
    "\n",
    "    def backward(self,X):\n",
    "        return X.reshape(self.shape)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "0uJcS2MHwK6M",
    "outputId": "32f159e4-54ac-4100-f256-57f97724f422"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward_shape: (20, 50)\n",
      "Backward_shape: (20, 2, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "TEST = np.zeros([20,2,5,5])\n",
    "flt = Flatten()\n",
    "flat_forward = flt.forward(TEST)\n",
    "print('Forward_shape:',flat_forward.shape)\n",
    "print('Backward_shape:',flt.backward(flat_forward).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fux5jvxuwK6N"
   },
   "source": [
    "### 【Problem 6】Training and Estimation\n",
    "Use the Conv2d you created to train and estimate MNIST and calculate the Accuracy.\n",
    "\n",
    "Please aim to make it work first, even if the accuracy is low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "hnkAOmCEwK6N"
   },
   "outputs": [],
   "source": [
    "# Scratch CNN\n",
    "class Scratch2dCNNClassifier():\n",
    "    \"\"\"\n",
    "    N-Layer Convolutional Neural Network Classifier\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    self.n_epoch : epoch number\n",
    "    self.n_batch : Number of batches\n",
    "    self.verbose : Visualizing the learning process\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self, NN, CNN, n_epoch=5, n_batch=1, verbose = False):\n",
    "        # Parameters\n",
    "        self.n_epoch = n_epoch\n",
    "        self.n_batch = n_batch\n",
    "        self.verbose = verbose\n",
    "        self.log_loss = np.zeros(self.n_epoch)\n",
    "        self.log_acc = np.zeros(self.n_epoch)\n",
    "        self.NN = NN\n",
    "        self.CNN = CNN\n",
    "    \n",
    "    #Defining the loss function\n",
    "    def loss_function(self,y,yt):\n",
    "        delta = 1e-7\n",
    "        return -np.mean(yt*np.log(y+delta))\n",
    "    \n",
    "    #Defining the metric for evaluating our model\n",
    "    def accuracy(self,Z,Y):\n",
    "        return accuracy_score(Y,Z)\n",
    "                \n",
    "    def fit(self, X, y, X_val=False, y_val=False):\n",
    "        \"\"\"\n",
    "        Train a neural network classifier.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray of the following form, shape (n_samples, n_features)\n",
    "            Features of training data\n",
    "        y : ndarray of the following form, shape (n_samples, )\n",
    "            Correct answer value of training data\n",
    "        X_val : ndarray of the following form, shape (n_samples, n_features)\n",
    "            Features of validation data\n",
    "        y_val : ndarray of the following form, shape (n_samples, )\n",
    "            Correct value of validation data\n",
    "        \"\"\"\n",
    "        for epoch in range(self.n_epoch):\n",
    "            # Mini-batch processing\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.n_batch)\n",
    "            \n",
    "            self.loss = 0\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                                \n",
    "                # Forward propagation\n",
    "                forward_data = mini_X_train[:,np.newaxis,:,:]\n",
    "                \n",
    "                # Conv\n",
    "                for layer in range(len(self.CNN)):\n",
    "                    forward_data = self.CNN[layer].forward(forward_data)\n",
    "                \n",
    "                # Flatten\n",
    "                flt = Flatten()\n",
    "                forward_data = flt.forward(forward_data)\n",
    "                \n",
    "                # NN\n",
    "                for layer in range(len(self.NN)):\n",
    "                    forward_data = self.NN[layer].forward(forward_data)\n",
    "                    \n",
    "                # Predicted value\n",
    "                Z = forward_data\n",
    "                \n",
    "                # Back propagation\n",
    "                backward_data = (Z - mini_y_train)/self.n_batch\n",
    "                for layer in range(len(self.NN)-1,-1,-1):\n",
    "                    backward_data = self.NN[layer].backward(backward_data)\n",
    "                    \n",
    "                backward_data = flt.backward(backward_data)\n",
    "                \n",
    "                for layer in range(len(self.CNN)-1,-1,-1):\n",
    "                    backward_data = self.CNN[layer].backward(backward_data)\n",
    "                \n",
    "                # Loss function\n",
    "                self.loss += self.loss_function(Z,mini_y_train)\n",
    "                \n",
    "            self.log_loss[epoch] = self.loss/len(get_mini_batch)\n",
    "            self.log_acc[epoch] = self.accuracy(self.predict(X),np.argmax(y,axis=1))\n",
    "            \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Estimate using a neural network classifier.。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray of the following form, shape (n_samples, n_features)\n",
    "            Sample\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            ndarray of the following, shape (n_samples, 1)\n",
    "            Estimation results\n",
    "        \"\"\"\n",
    "        pred_data = X[:,np.newaxis,:,:]\n",
    "        \n",
    "        # Conv\n",
    "        for layer in range(len(self.CNN)):\n",
    "            pred_data = self.CNN[layer].forward(pred_data)\n",
    "                \n",
    "        pred_data = flt.forward(pred_data)\n",
    "        \n",
    "        # NN\n",
    "        for layer in range(len(self.NN)):\n",
    "            pred_data = self.NN[layer].forward(pred_data)\n",
    "            \n",
    "        return np.argmax(pred_data,axis=1) #using argmax to get the indice of the highest value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Nd2itkg0wK6N"
   },
   "outputs": [],
   "source": [
    "# All bonding layers\n",
    "NN = {0:FC(7840, 400, HeInitializer(), AdaGrad(0.01), ReLU()),\n",
    "      1:FC(400, 200, HeInitializer(), AdaGrad(0.01), ReLU()),\n",
    "      2:FC(200, 10, SimpleInitializer(0.01), AdaGrad(0.01), Softmax()),\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "VA0duXqdwK6N"
   },
   "outputs": [],
   "source": [
    "# Convolutional layers\n",
    "CNN = {0:SimpleConv2d(F=10, C=1, FH=3, FW=3, P=1, S=1,\n",
    "                      initializer=SimpleInitializerConv2d(),\n",
    "                      optimizer=SGD(),\n",
    "                      activation=ReLU())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "at4_QFo8wK6O"
   },
   "outputs": [],
   "source": [
    "# Learning\n",
    "cnn1 = Scratch2dCNNClassifier(NN=NN,CNN=CNN,n_epoch=10,n_batch=200,verbose=False)\n",
    "\n",
    "cnn1.fit(X_train[0:1000],y_train[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "Ou7d7r_BwK6O",
    "outputId": "ce01563d-16df-4914-a9bc-eb321c6f15b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.870\n"
     ]
    }
   ],
   "source": [
    "# Estimate\n",
    "y_pred = cnn1.predict(X_valid[0:100])\n",
    "\n",
    "# Positive solution rate\n",
    "accuracy = accuracy_score(np.argmax(y_valid[0:100],axis=1), y_pred)\n",
    "print('accuracy:{:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "9QTh7iR_wK6O",
    "outputId": "d201b5c1-80ea-402c-a760-4db5f671a5c1",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the loss function for each epoch\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "fig=plt.subplots(figsize=(16,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('LOSS')\n",
    "plt.plot(cnn1.log_loss,'bo--')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('ACC')\n",
    "plt.plot(cnn1.log_acc,'rs--');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IY5QpsTUwK6O"
   },
   "source": [
    "* As a result of running it on the mini-data, the LOSS is coming down, and the percentage of correct answers, as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8d0oPUItwK6O"
   },
   "source": [
    "### 【Problem 7】(Advanced Problem) LeNet\n",
    "When performing image recognition with CNNs, it is common to use a well-known structure rather than thinking about filter size and number of layers from scratch. The most historically important one is LeNet from 1998, although it is no longer in practical use today. You can recreate this structure and run it against MNIST to calculate Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pOf0X16ywK6P"
   },
   "outputs": [],
   "source": [
    "# LeNet structure\n",
    "# Convolutional layers\n",
    "LeNetCNN = {0:SimpleConv2d(F=6, C=1, FH=5, FW=5, P=2, S=1,\n",
    "                           initializer=SimpleInitializerConv2d(),\n",
    "                           optimizer=SGD(),\n",
    "                           activation=ReLU()),\n",
    "            1:MaxPool2D(P=2),\n",
    "            2:SimpleConv2d(F=16, C=6, FH=5, FW=5, P=2, S=1,\n",
    "                           initializer=SimpleInitializerConv2d(),\n",
    "                           optimizer=SGD(),\n",
    "                           activation=ReLU()),\n",
    "            3:MaxPool2D(P=2),}\n",
    "\n",
    "# All bonding layers\n",
    "LeNetNN = {0:FC(784, 120, HeInitializer(), AdaGrad(0.01), ReLU()),\n",
    "           1:FC(120, 84, HeInitializer(), AdaGrad(0.01), ReLU()),\n",
    "           2:FC(84, 10, SimpleInitializer(0.01), AdaGrad(0.01), Softmax()),}\n",
    "\n",
    "# Learning\n",
    "LeNet = Scratch2dCNNClassifier(NN=LeNetNN,CNN=LeNetCNN,\n",
    "                               n_epoch=30,n_batch=20,verbose=False)\n",
    "\n",
    "LeNet.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VILRPYu0wK6P",
    "outputId": "fd9275b1-d23e-4c6c-c413-0737fa31c640"
   },
   "outputs": [],
   "source": [
    "# Estimate\n",
    "y_pred_LeNet = LeNet.predict(X_valid)\n",
    "\n",
    "# Positive solution rate\n",
    "accuracy = accuracy_score(np.argmax(y_valid,axis=1), y_pred_LeNet)\n",
    "print('accuracy:{:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XjhAxBiVwK6P",
    "outputId": "7e904a95-d629-4f2c-ea2f-7bc16db0cc97"
   },
   "outputs": [],
   "source": [
    "# Visualize the loss function for each epoch\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "fig=plt.subplots(figsize=(16,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('LOSS')\n",
    "plt.plot(LeNet.log_loss,'bo--')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('ACC')\n",
    "plt.plot(LeNet.log_acc,'rs--');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jB5bstALwK6Q"
   },
   "source": [
    "### 【Problem 8】(Advanced Problem) Survey of well-known image recognition models\n",
    "Some of the most popular CNN structures are AlexNet (2012), VGG16 (2014), and so on.  \n",
    "Many of these models are already available in frameworks.\n",
    "\n",
    "Please do some quick research and summarize what's available. It is a good idea to at least look at the names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZ0h_ikewK6Q"
   },
   "source": [
    "Famous CNN structures\n",
    "* AlexNet(2012)\n",
    "* ZFNet(2013)\n",
    "* GoogleNet(2014)\n",
    "* VGGNet(2014)\n",
    "* ResNet(2015)\n",
    "* SENet(2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtP8R-9hwK6Q"
   },
   "source": [
    "### 【Problem 9】Calculating output size and number of parameters\n",
    "When building a CNN model, it is necessary to calculate the number of features in advance at the stage of inputting them into the all-connected layer.\n",
    "\n",
    "Also, when dealing with huge models, the calculation of the number of parameters becomes essential due to memory and computation speed. The framework can display the number of parameters for each layer, but without understanding the meaning, it is impossible to make appropriate adjustments.\n",
    "\n",
    "Calculate the output size and the number of parameters for the following three convolutional layers. For the number of parameters, also consider the bias term.\n",
    "\n",
    "1.\n",
    "\n",
    "* Input size : 144x144, 3 channels\n",
    "* Filter size : 3×3, 6 channels\n",
    "* Stride : 1\n",
    "* Padding : None\n",
    "\n",
    "→ Output size : 6×142×142, Number of parameters : 168 (Weight 162, Bias 6)\n",
    "\n",
    "2.\n",
    "\n",
    "* Input size : 60×60, 24 channels\n",
    "* Filter size: 3×3, 48 channels\n",
    "* Stride : 1\n",
    "* Padding : None\n",
    "\n",
    "→ Output size : 48×58×58, Number of parameters : 10416(Weight 10368, Bias 48)\n",
    "\n",
    "3.\n",
    "\n",
    "* Input size: 20x20, 10 channels\n",
    "* Filter size: 3×3, 20 channels\n",
    "* Stride : 2\n",
    "* Padding : None\n",
    "\n",
    "→ Output size: 20x9x9, Number of parameters: 1820 (weights 1800, bias 20)\n",
    "\n",
    "The last example is a case where the convolution cannot be done just right. The framework sometimes does not look at the extra pixels, so please consider that case in your calculations. This is an example of why this kind of setting is not desirable, because it will result in missing edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3_MAuK6wK6Q"
   },
   "source": [
    "### 【Problem 10】(Advanced Problem) Survey on Filter Size\n",
    "Convolutional layers have a hyperparameter called filter size, but in 2D convolutional layers the majority of use nowadays is 3×3 and 1×1. Please look up each of the following, or come up with your own explanation.\n",
    "\n",
    "* Why 3×3 filters are commonly used instead of larger ones such as 7×7  \n",
    "  → Because the number of parameters would be huge. (Size squared)  \n",
    "    Because the purpose of convolution is to extract features (including positional relationships) between input parameters.\n",
    "    Increasing the filter size is contrary to the purpose.\n",
    "  \n",
    "  \n",
    "* The effect of a 1×1 filter with no height or width direction  \n",
    "  → By reducing the number of output channels from the input channels, the number of parameters can be reduced.\n",
    "  \n",
    "\n",
    "* The effect of a 1×1 filter with no height or width direction.  \n",
    "  → If the number is odd, the center of the filter is defined, but if the number is even, the center is not defined."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "mep_day19_CNN2_en.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "目次",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "428px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
